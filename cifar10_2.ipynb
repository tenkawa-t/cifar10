{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cifar10_2.ipynb","provenance":[],"mount_file_id":"1anrykPe5pucuFkZfdWhcXZ8hVPbmqHEp","authorship_tag":"ABX9TyO+LjSaCtxqFYyyMZLMq/LF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"XnnOwsSuUMso","executionInfo":{"status":"ok","timestamp":1604751735618,"user_tz":-540,"elapsed":8717,"user":{"displayName":"Tenkawa Tomoyuki","photoUrl":"","userId":"08067809450853350491"}},"outputId":"cca4b16b-9e44-45d3-8c45-4e151417348b","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install albumentations\n","!pip install torch\n","!pip install torchvision\n","# model.py\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pandas as pd\n","\n","'''ResNet in PyTorch.\n","\n","For Pre-activation ResNet, see 'preact_resnet.py'.\n","\n","Reference:\n","[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n","\tDeep Residual Learning for Image Recognition. arXiv:1512.03385\n","'''\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion * planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion * planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion * planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion * planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512 * block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1] * (num_blocks - 1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","\n","\n","def ResNet18():\n","    return ResNet(BasicBlock, [2, 2, 2, 2])\n","\n","\n","def ResNet34():\n","    return ResNet(BasicBlock, [3, 4, 6, 3])\n","\n","\n","def ResNet50():\n","    return ResNet(Bottleneck, [3, 4, 6, 3])\n","\n","\n","def ResNet101():\n","    return ResNet(Bottleneck, [3, 4, 23, 3])\n","\n","\n","def ResNet152():\n","    return ResNet(Bottleneck, [3, 8, 36, 3])\n","\n","\n","def test():\n","    net = ResNet18()\n","    y = net(torch.randn(1, 3, 32, 32))\n","    print(y.size())\n","\n","\n","# test()\n","'''Train CIFAR10 with PyTorch.'''\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.backends.cudnn as cudnn\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.backends.cudnn as cudnn\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","import os\n","import argparse\n","from sklearn.metrics import classification_report\n","\n","import os\n","import argparse\n","\n","# data augment\n","# 訓練誤差\n","# lr 　optimizer 初期値　activation\n","# 過学習\n","# dataaugment validation\n","import cv2\n","import matplotlib.pyplot as plt\n","import albumentations as albu\n","from albumentations import (\n","    Compose, HorizontalFlip, CLAHE, HueSaturationValue,\n","    RandomBrightness, RandomContrast, RandomGamma,\n","    ToFloat, ShiftScaleRotate\n",")\n","import numpy as np\n","from PIL import Image\n","\n","\n","# def load_data(data_dir):\n","def load_data(albu_list):\n","    albu_transforms = albu.Compose(albu_list)\n","\n","    def albumentations_transform(image, transform=albu_transforms):\n","        if transform:\n","            image_np = np.array(image)\n","            augmented = transform(image=image_np)\n","            image = Image.fromarray(augmented['image'])\n","        return image\n","\n","    transform_train = transforms.Compose([\n","        transforms.Lambda(albumentations_transform),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","    ])\n","\n","    transform_test = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","    ])\n","    train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                             download=True, transform=transform_train)\n","    train_loader = torch.utils.data.DataLoader(train_set, batch_size=128,\n","                                               shuffle=True, num_workers=2)\n","\n","    test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                            download=True, transform=transform_test)\n","    test_loader = torch.utils.data.DataLoader(test_set, batch_size=100,\n","                                              shuffle=False, num_workers=2)\n","\n","    # train_set = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform_train)\n","    # train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True, num_workers=0)\n","    # test_set = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform_test)\n","    # test_loader = torch.utils.data.DataLoader(test_set, batch_size=100, shuffle=False, num_workers=0)\n","    class_names = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","    return train_loader, test_loader, class_names\n","\n","\n","'''Train CIFAR10 with PyTorch.'''\n","\n","\n","def main():\n","    dataset_name = 'CIFAR10'\n","    model_name = 'ResNet18'\n","    model_ckpt_dir = '/content/drive/My Drive/cifar10/experiment/aug/checkpoints'\n","    model_ckpt_path_temp = '/content/drive/My Drive/cifar10/experiment/aug/checkpoints/{}_{}_{}_epoch={}.pth'\n","    n_epoch = 100\n","    lr = 0.001\n","\n","    # Make directory.\n","    os.makedirs(model_ckpt_dir, exist_ok=True)\n","    # Validate paths.\n","    # Set device.\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    # Load dataset.\n","\n","    \n","    albu_list = [HorizontalFlip(p=0.5),\n","                 RandomContrast(limit=0.2, p=0.5),\n","                 RandomGamma(gamma_limit=(80, 120), p=0.5),\n","                 RandomBrightness(limit=0.2, p=0.5),\n","                 HueSaturationValue(hue_shift_limit=5, sat_shift_limit=20, val_shift_limit=10, p=.9),\n","                 #  CLAHE(p=1.0, clip_limit=2.0),\n","                 ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, border_mode=cv2.BORDER_REFLECT_101,\n","                                  p=0.8)\n","                 ]\n","    albu_list_name = [\n","        \"HorizontalFlip\",\n","        \"RandomContrast\",\n","        \"RandomGamma\",\n","        \"RandomBrightness\",\n","        \"HueSaturationValue\",\n","        \"CLAHE\",\n","        \"ShiftScaleRotate\"\n","    ]\n","    \n","    for albu, albuname in zip(albu_list, albu_list_name):\n","        train_loader, test_loader, class_names = load_data(list(albu))\n","    \n","        # Set a model.\n","        model = get_model(model_name)\n","        model = model.to(device)\n","    \n","        # Set loss function and optimization function.\n","        criterion = nn.CrossEntropyLoss()\n","        # optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n","        optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=5e-4, eps=1e-08, amsgrad=False)\n","        # Train and test.\n","        list_test = []\n","        for epoch in range(n_epoch):\n","            # Train and test a model.\n","            train_acc, train_loss = train(model, device, train_loader, criterion, optimizer)\n","            test_acc, test_loss = test(model, device, test_loader, criterion)\n","    \n","            # Output score.\n","            stdout_temp = 'epoch: {:>3}, train acc: {:<8}, train loss: {:<8}, test acc: {:<8}, test loss: {:<8}'\n","            print(stdout_temp.format(epoch + 1, train_acc, train_loss, test_acc, test_loss))\n","            # Save a model checkpoint.\n","            model_ckpt_path = model_ckpt_path_temp.format(dataset_name, model_name, albuname, epoch + 1)\n","            torch.save(model.state_dict(), model_ckpt_path)\n","    \n","            print('Saved a model checkpoint at {}'.format(model_ckpt_path))\n","            print('')\n","            list_temp = []\n","            list_temp = [epoch + 1, model_ckpt_path, train_acc, train_loss, test_acc, test_loss]\n","            list_test.append(list_temp)\n","        df = pd.DataFrame(list_test)\n","        df.columns = [\"epoch\", model_ckpt_path, \"train_acc\", \"train_loss\", \"test_acc\", \"test_loss\"]\n","        df.to_csv(f\"{model_ckpt_dir}_{model_name}_{albuname}_adam_test.csv\")\n","\n","\n","def train(model, device, train_loader, criterion, optimizer):\n","    model.train()\n","\n","    output_list = []\n","    target_list = []\n","    running_loss = 0.0\n","    for batch_idx, (inputs, targets) in enumerate(train_loader):\n","        # Forward processing.\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        outputs = model(inputs)\n","        loss = criterion(outputs, targets)\n","\n","        # Backward processing.\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Set data to calculate score.\n","        output_list += [int(o.argmax()) for o in outputs]\n","        target_list += [int(t) for t in targets]\n","        running_loss += loss.item()\n","\n","        # Calculate score at present.\n","        train_acc, train_loss = calc_score(output_list, target_list, running_loss, train_loader)\n","        if batch_idx % 10 == 0 and batch_idx != 0:\n","            stdout_temp = 'batch: {:>3}/{:<3}, train acc: {:<8}, train loss: {:<8}'\n","            print(stdout_temp.format(batch_idx, len(train_loader), train_acc, train_loss))\n","\n","    # Calculate score.\n","    train_acc, train_loss = calc_score(output_list, target_list, running_loss, train_loader)\n","\n","    return train_acc, train_loss\n","\n","\n","def test(model, device, test_loader, criterion):\n","    model.eval()\n","\n","    output_list = []\n","    target_list = []\n","    running_loss = 0.0\n","    for batch_idx, (inputs, targets) in enumerate(test_loader):\n","        # Forward processing.\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        outputs = model(inputs)\n","        loss = criterion(outputs, targets)\n","\n","        # Set data to calculate score.\n","        output_list += [int(o.argmax()) for o in outputs]\n","        target_list += [int(t) for t in targets]\n","        running_loss += loss.item()\n","\n","    test_acc, test_loss = calc_score(output_list, target_list, running_loss, test_loader)\n","\n","    return test_acc, test_loss\n","\n","\n","def get_model(model_name):\n","    if model_name == 'VGG19':\n","        model = VGG('VGG19')\n","    elif model_name == 'ResNet18':\n","        model = ResNet18()\n","    elif model_name == 'PreActResNet18':\n","        model = PreActResNet18()\n","    elif model_name == 'GoogLeNet':\n","        model = GoogLeNet()\n","    elif model_name == 'DenseNet121':\n","        model = DenseNet121()\n","    elif model_name == 'ResNeXt29_2x64d':\n","        model = ResNeXt29_2x64d()\n","    elif model_name == 'MobileNet':\n","        model = MobileNet()\n","    elif model_name == 'MobileNetV2':\n","        model = MobileNetV2()\n","    elif model_name == 'DPN92':\n","        model = DPN92()\n","    elif model_name == 'ShuffleNetG2':\n","        model = ShuffleNetG2()\n","    elif model_name == 'SENet18':\n","        model = SENet18()\n","    elif model_name == 'ShuffleNetV2':\n","        model = ShuffleNetV2(1)\n","    elif model_name == 'EfficientNetB0':\n","        model = EfficientNetB0()\n","    else:\n","        print('{} does NOT exist in repertory.'.format(model_name))\n","        sys.exit(1)\n","\n","    return model\n","\n","\n","def calc_score(output_list, target_list, running_loss, data_loader):\n","    # Calculate accuracy.\n","    result = classification_report(output_list, target_list, output_dict=True)\n","    acc = round(result['weighted avg']['f1-score'], 6)\n","    loss = round(running_loss / len(data_loader.dataset), 6)\n","\n","    return acc, loss"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: albumentations in /usr/local/lib/python3.6/dist-packages (0.1.12)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from albumentations) (4.1.2.30)\n","Requirement already satisfied: imgaug<0.2.7,>=0.2.5 in /usr/local/lib/python3.6/dist-packages (from albumentations) (0.2.6)\n","Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.18.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations) (1.4.1)\n","Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (0.16.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (1.15.0)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (3.2.2)\n","Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (7.0.0)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.1)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.5)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.1.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.10.0)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (4.4.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.7)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.8.1+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.5)\n","Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.7.0+cu101)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision) (0.7)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision) (0.16.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision) (3.7.4.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3Z2ibx6rXt-c","executionInfo":{"status":"ok","timestamp":1604750427516,"user_tz":-540,"elapsed":878,"user":{"displayName":"Tenkawa Tomoyuki","photoUrl":"","userId":"08067809450853350491"}},"outputId":"37168d80-3f36-4bf3-984c-d595f3cdf062","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g6VROrRVlECR","executionInfo":{"status":"error","timestamp":1604753063822,"user_tz":-540,"elapsed":723,"user":{"displayName":"Tenkawa Tomoyuki","photoUrl":"","userId":"08067809450853350491"}},"outputId":"fa0b7dee-fd30-419e-8558-f38b14253418","colab":{"base_uri":"https://localhost:8080/","height":294}},"source":["main()"],"execution_count":14,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-13-201ed20340ba>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0malbu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malbuname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malbu_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malbu_list_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malbu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;31m# Set a model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'HorizontalFlip' object is not iterable"]}]},{"cell_type":"code","metadata":{"id":"B8_akXa-vHvX"},"source":[""],"execution_count":null,"outputs":[]}]}